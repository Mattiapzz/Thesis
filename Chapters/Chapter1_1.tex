\section{Optimal Control Problems}
%
Optimal control problem, also known as dynamic optimisation, are minimisation problem where the variables and parameters change with time. Dynamic systems are characterized by the states and often are controlled by a convenient choice of inputs (controls).\\
Dynamic optimisation aims to compute those controls and states for a dynamic system over a time interval to minimise one or more performance indexes. In other words, the input is chosen to optimize (minimize) an objective function while complying to constraint equations.\\
Optimal control problems are challenging from the theoretical point of view and of practical interest. However, due to dimensionality and complexity of the system of equations the application in real problems and the industrial environment is still not so widespread.\\
In general, OPC can be continuous or discrete, linear or non-linear, time-variant or time-invariant. However, in this thesis are addressed only optimal control problems that are continuous time-variant and highly non-linear. Those properties will be discussed in the following sections.\\
In general, there are four main approaches to solve continuous-time OPC: state space approach, direct methods, indirect methods and differential dynamic programming.
%
\subsection{State-space Approaches}
%
State-space approaches follow the principle of optimality for which each sub-arc of an optimal trajectory must be optimal. In literature, those are referred to as the Hamilton-Jacobi-Bellman (HJB) equation. However, the problem needs numerical methods to be solved, moreover, a solution can be found only for small dimension problems due to \textit{course of dimensionality}. There is no practical application of this method to solve highly non-linear problem as a dynamic optimisation of a motorcycle model.
% QUOTES MISSING
%
\subsection{Direct Method}
%
Direct methods discretise the original optimal control problem into a non-linear programming problem (NLP). In other words, the OPC is transformed into a discrete-time system that can be solved using numerical schemes and optimization techniques, namely Initial Value Solver (IVS) and Sequential Quadratic Programming (SQP) \cite{bertolazzi2005symbolic}
The main advantage of direct methods is the possibility to use inequality constraints even in case of changes in the constraints active set ( activation/deactivation)\cite{biral2016notes}\\
Direct methods are easier to implement compared to the other three categories and this is one of the reasons why they are by far the most widespread. In fact, almost $90\%$ of the available optimal control software rely on the direct method. \cite{rao2009survey,rodrigues2014optimal}
One most common software is GPOPS-II\cite{patterson2014gpops}, a tool developed by Patterson and Rao. Other worth citing software are ACADO Toolkit\cite{Houska2011a} and CasADi\cite{Andersson2019}.\\
Most of the previously cited tool make use of IPOPT for the solution of the non-linear system of equations.\cite{wachter2006implementation}
%
%%%
\if FALSE
Brief descriptions
of three of the direct methods â€“ single shooting, multiple shooting, and collocation
\fi
%
\subsection{Indirect Methods}
%
The indirect method exploits the necessary condition of optimality to derive a boundary value problem (BVP) in ordinary differential equations(ODE). Therefore the BVP can be solved numerically as a non-linear problem. The indirect method allows to first optimize and then discretise meaning that the problem con be firstly written in continuous time and discretised later using different discretisation techniques.\\
The class of indirect methods exploits the well-known calculus of variations and the Euler-Lagrange differential equations, and the so-called Pontryagin Maximum Principle.\cite{bertolazzi2006symbolic} \\
The numerical solution can be computed either by shooting techniques (single/multiple shooting) or by collocation.
The major drawbacks of indirect methods are that the problem could be difficult to solve or unstable due to the nature of the underlying differential equations (non-linearity and instability) and the changes in control structure (active constraints in specific arcs). Moreover, in some arcs, singularity arises therefore the DAE index increase leading to the necessity of specialized solution techniques. \cite{biral2016notes}
Biral \textit{et al.}\cite{biral2016notes} develop PINS, a software that transforms the boundary value problem in a non-linear system of equation using finite difference. The system is then solved with a dumped Newton method. PINS (PINS Is Not a Solver) is a software under copyright, but free for academic purposes. 
%
\subsection{Differential Dynamic Programming}
%
Differential Dynamic Programming (DDP) is a technique developed to overcome the limitation of the dynamic programming approach. The simple approach was developed firstly by Bellman and Dreyfus and it is based on Bellman's principle of optimality.\cite{bellman2015applied}\\
The DDP is a second-order shooting method where the cost function is approximated around a reference with a quadratic function.\cite{mayne1966second}\\ 
This approach is well known and dates back to 1966. A remarkable result has been obtained by Huang \textit{et al.}\cite{huang2014trajectory} where they use DDP approach to compute the trajectory of an autonomous vehicle with simple kinematics. However, as far as the author knows, it has never been used to solve the optimal control problem with complex dynamic models. Furthermore, there is no trace, in literature, of OCP concerning motorcycles solved using DDP.
%